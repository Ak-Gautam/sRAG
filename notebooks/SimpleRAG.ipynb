{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new about history, art, or science.\",\n",
    "    \"Attend a live music concert and feel the rhythm of your favorite genre, be it rock, jazz, or classical.\",\n",
    "    \"Go for a hike in nature and admire the beauty of the natural scenery, from mountains and forests to deserts and beaches.\",\n",
    "    \"Have a picnic with friends and share some laughs, good food, and great company in the outdoors.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant and tantalize your taste buds with exotic flavors.\",\n",
    "    \"Take a yoga class and stretch your body and mind, promoting relaxation and inner peace.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition, while getting exercise and socializing with others who share your passion for the sport.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in, to expand your knowledge and gain new skills.\",\n",
    "    \"Visit an amusement park and experience the thrill of riding roller coasters, bumper cars, and other exciting attractions.\",\n",
    "    \"Go stargazing on a clear night and marvel at the wonders of the universe.\",\n",
    "    \"Volunteer at a local charity and give back to your community.\",\n",
    "    \"Learn a new language and open yourself up to new cultures and experiences.\",\n",
    "    \"Take a road trip and explore new places, experiencing the beauty and diversity of the world around you.\",\n",
    "    \"Go camping under the stars and reconnect with nature.\",\n",
    "    \"Read a book and get lost in a captivating story.\",\n",
    "    \"Binge-watch a tv show or movie series and enjoy a relaxing escape.\",\n",
    "    \"Try a new hobby or activity, like painting, pottery, or playing a musical instrument.\",\n",
    "    \"Spend time with loved ones and create lasting memories.\",\n",
    "    \"Take a relaxing bath and unwind after a long day.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(query, document):\n",
    "    # Tokenize and count words\n",
    "    query_counts = Counter(query.lower().split())\n",
    "    doc_counts = Counter(document.lower().split())\n",
    "    \n",
    "    # Get the union of words\n",
    "    all_words = set(query_counts.keys()) | set(doc_counts.keys())\n",
    "    \n",
    "    # Create vectors\n",
    "    query_vec = np.array([query_counts.get(word, 0) for word in all_words])\n",
    "    doc_vec = np.array([doc_counts.get(word, 0) for word in all_words])\n",
    "    \n",
    "    # Compute dot product and norms\n",
    "    dot_product = np.dot(query_vec, doc_vec)\n",
    "    norm_query = np.linalg.norm(query_vec)\n",
    "    norm_document = np.linalg.norm(doc_vec)\n",
    "    \n",
    "    # Compute and return the cosine similarity\n",
    "    if norm_query == 0 or norm_document == 0:\n",
    "        return 0.0  # Handle edge case where one vector is zero\n",
    "    return dot_product / (norm_query * norm_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_response(query, corpus):\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        similarity = cosine_similarity(user_input, doc)\n",
    "        similarities.append(similarity)\n",
    "    return corpus_of_documents[similarities.index(max(similarities))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I like to hike\"\n",
    "return_response(user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_document = return_response(user_input, corpus_of_documents)\n",
    "full_response = []\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xformers==0.0.25 numpy==1.23.5 pyarrow==14.0.1 fsspec==2023.6.0 torch -q\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" -q\n",
    "!pip install --no-deps trl peft accelerate bitsandbytes -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"glouriousgautam/Qwen2-1.5b-oasstguanaco-qdora-merged\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"chatml\", # Supports zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n",
    "    mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, # ShareGPT style\n",
    "    map_eos_token = True, # Maps <|im_end|> to  instead\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [\n",
    "    {\"from\": \"human\", \"value\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"from\": \"human\", \"value\": prompt.format(user_input=user_input, relevant_document=relevant_document)},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128, use_cache = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similar_documents(query: str, corpus: List[str], top_n: int = 1) -> List[str]:\n",
    "    # Preprocess the query and corpus\n",
    "    preprocessed_query = query.lower().strip()\n",
    "    preprocessed_corpus = [doc.lower().strip() for doc in corpus]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    corpus_vectors = vectorizer.fit_transform(preprocessed_corpus)\n",
    "    query_vector = vectorizer.transform([preprocessed_query])\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarities = cosine_similarity(query_vector, corpus_vectors).flatten()\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "\n",
    "    return [corpus[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_similar_documents(\"What is a leisure activity that you like?\", corpus_of_documents)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
